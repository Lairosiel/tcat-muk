{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import / Setup\n",
    "\n",
    "If you are using this repository without any processed input data, you will need to create fresh data using Google's MapsAPIV3.\n",
    "This requires a Google API Key, available at Google's Cloud Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'SETME'\n",
    "API_TIMEOUT_S = 10\n",
    "API_USER_AGENT = 'tcat-pridemonth.muk.uni-passau.de'\n",
    "API_CSV_OUTPUT = 'geolocated.csv'\n",
    "\n",
    "CSV_INPUT = 'tcat_input.csv'\n",
    "CSV_OUTPUT = 'country_coded.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopy as gp\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "We require 3 functions to fetch data from Google's MapsAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_fn(fn):\n",
    "    \"\"\"\n",
    "    Retry a given functions up to 5 times.\n",
    "    \n",
    "    Args:\n",
    "        *args: The arguments to the wrapped function.\n",
    "        retries: The number of retries we have left. Defaults to 5.\n",
    "        **kwargs: All other keyword arguments, passed on to the given fn.\n",
    "        \n",
    "    Returns:\n",
    "        Whatever the given function returns, or \"ERROR\",\n",
    "        if we run out of retries.\n",
    "    \"\"\"\n",
    "    def wrap_fn(*args, retries=5, **kwargs):\n",
    "        \"\"\"Function wrapper that does the retrying.\"\"\"\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except Exception:\n",
    "            if retries > 0:\n",
    "                return wrap_fn(*args, retries=retries-1, **kwargs)\n",
    "            else:\n",
    "                return \"ERROR\"\n",
    "            \n",
    "    return wrap_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(fn, src_col, tgt_col, row):\n",
    "    \"\"\"\n",
    "    Apply a fn to the column of a dataframe row.\n",
    "    \n",
    "    Use this in combination with functools.partial to create a function usable by\n",
    "    DataSeries.apply().\n",
    "    \n",
    "    Example:\n",
    "        series.apply(functools.partial(foo, 'a', 'b'))\n",
    "    \n",
    "    Args:\n",
    "        fn: The functiont to apply.\n",
    "        src_col: The source column name.\n",
    "        tgt_col: The target column name.\n",
    "        row: The input row.\n",
    "    \"\"\"\n",
    "    row[tgt_col] = row[src_col].apply(fn)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_apply(df, func, cores=8, partitions=24):\n",
    "    \"\"\"\n",
    "    Apply a function on all rows of a data frame, in parallel.\n",
    "    \n",
    "    Args:\n",
    "        df: The dataframe we operate on.\n",
    "        func: The function to apply.\n",
    "        cores: The number of processes we run in parallel.\n",
    "        partitions: The number of data partitions we create.\n",
    "    \"\"\"\n",
    "    df_split = np.array_split(df, partitions)\n",
    "    pool = Pool(cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not query the Google API, if the processed input data is already available (API_CSV_OUTPUT).\n",
    "If you wish to regenerate all data from scratch, just delete the file at API_CSV_OUTPUT and provide a\n",
    "API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(API_CSV_OUTPUT):\n",
    "    df = pd.read_csv(CSV_INPUT, index_col='id')\n",
    "    dff = df[~ pd.isnull(df.location)]\n",
    "\n",
    "    geolocator = gp.GoogleV3(api_key=API_KEY, user_agent=USER_AGENT, timeout=10)\n",
    "    geocode = retry_fn(geolocator.geocode)\n",
    "    geolocated = parallel_apply(dff, partial(process_row, geocode, 'location', 'geolocation'))\n",
    "    geolocated.to_csv(API_CSV_OUTPUT)\n",
    "else:\n",
    "    geolocated = pd.read_csv(API_CSV_OUTPUT, index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "\n",
    "We filter all data that came back as invalid from the Google API and extract all unnecessary data from the result column.\n",
    "For that we split the column data that came from Google Maps at the rightmost ',' at most once. This should provide us with\n",
    "the country in most cases.\n",
    "\n",
    "You need to take special care or do further post-processing to make sure that your data does not contain invalid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_fun(cell):\n",
    "    content_split = cell.rsplit(',', maxsplit=1)\n",
    "    return content_split[-1]\n",
    "\n",
    "geolocated = geolocated[~ pd.isnull(geolocated.geolocation)]\n",
    "geolocated['country'] = geolocated['geolocation'].apply(cell_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all data sorted by the new column contry to CSV_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocated.sort_values('country').to_csv(CSV_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
